"""
æ™ºè°±æ¸…è¨€APIå®¢æˆ·ç«¯
"""
import requests
import json
from typing import Dict, List, Any, Optional
from config import ZHIPU_API_KEY, ZHIPU_API_URL

class ZhipuClient:
    """æ™ºè°±æ¸…è¨€APIå®¢æˆ·ç«¯"""
    
    def __init__(self):
        self.api_key = ZHIPU_API_KEY
        self.base_url = ZHIPU_API_URL
        self.headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
    
    def _call_api(self, messages: List[Dict[str, str]], temperature: float = 0.7) -> str:
        """è°ƒç”¨æ™ºè°±æ¸…è¨€API"""
        data = {
            "model": "glm-4.5",
            "messages": messages,
            "temperature": temperature,
            "max_tokens": 4000
        }
        
        try:
            response = requests.post(
                self.base_url,
                headers=self.headers,
                json=data,
                timeout=120  # å¢åŠ è¶…æ—¶æ—¶é—´åˆ°120ç§’
            )
            response.raise_for_status()
            
            result = response.json()
            return result["choices"][0]["message"]["content"]
        
        except Exception as e:
            raise Exception(f"APIè°ƒç”¨å¤±è´¥: {str(e)}")
    
    def parse_resume(self, resume_content: str) -> Dict[str, Any]:
        """è§£æç®€å†å†…å®¹"""
        prompt = f"""
        è¯·è§£æä»¥ä¸‹ç®€å†å†…å®¹ï¼Œæå–å…³é”®ä¿¡æ¯å¹¶ä»¥JSONæ ¼å¼è¿”å›ï¼š
        
        ç®€å†å†…å®¹ï¼š
        {resume_content}
        
        è¯·è¿”å›ä»¥ä¸‹æ ¼å¼çš„JSONï¼š
        {{
            "name": "å€™é€‰äººå§“å",
            "contact_info": {{
                "phone": "ç”µè¯å·ç ",
                "email": "é‚®ç®±",
                "location": "æ‰€åœ¨åœ°"
            }},
            "summary": "ä¸ªäººç®€ä»‹",
            "skills": ["æŠ€èƒ½1", "æŠ€èƒ½2", "æŠ€èƒ½3"],
            "experience": [
                {{
                    "company": "å…¬å¸åç§°",
                    "position": "èŒä½",
                    "duration": "å·¥ä½œæ—¶é—´",
                    "description": "å·¥ä½œæè¿°"
                }}
            ],
            "education": [
                {{
                    "degree": "å­¦ä½",
                    "major": "ä¸“ä¸š",
                    "school": "å­¦æ ¡",
                    "year": "æ¯•ä¸šå¹´ä»½"
                }}
            ],
            "projects": ["é¡¹ç›®1", "é¡¹ç›®2"],
            "certifications": ["è¯ä¹¦1", "è¯ä¹¦2"]
        }}
        
        è¯·ç¡®ä¿è¿”å›æœ‰æ•ˆçš„JSONæ ¼å¼ã€‚
        """
        
        messages = [
            {"role": "user", "content": prompt}
        ]
        
        response = self._call_api(messages)
        
        try:
            # æå–JSONéƒ¨åˆ†
            json_start = response.find('{')
            json_end = response.rfind('}') + 1
            json_str = response[json_start:json_end]
            
            return json.loads(json_str)
        except:
            # å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›é»˜è®¤ç»“æ„
            return {
                "name": "æœªçŸ¥",
                "contact_info": {},
                "summary": resume_content[:200] + "...",
                "skills": [],
                "experience": [],
                "education": [],
                "projects": [],
                "certifications": []
            }
    
    def analyze_match(self, resume_data: Dict[str, Any], job_description: str) -> Dict[str, Any]:
        """åˆ†æç®€å†ä¸èŒä½æè¿°çš„åŒ¹é…åº¦"""
        prompt = f"""
        è¯·åˆ†æä»¥ä¸‹å€™é€‰äººç®€å†ä¸èŒä½æè¿°çš„åŒ¹é…åº¦ï¼š
        
        å€™é€‰äººä¿¡æ¯ï¼š
        {json.dumps(resume_data, ensure_ascii=False, indent=2)}
        
        èŒä½æè¿°ï¼š
        {job_description}
        
        è¯·è¿”å›ä»¥ä¸‹æ ¼å¼çš„JSONåˆ†æç»“æœï¼š
        {{
            "match_score": 85.5,
            "skills_analysis": {{
                "required_skills": ["Python", "æœºå™¨å­¦ä¹ ", "æ•°æ®åˆ†æ"],
                "candidate_skills": ["Python", "Java", "æ•°æ®åˆ†æ"],
                "matched_skills": ["Python", "æ•°æ®åˆ†æ"],
                "missing_skills": ["æœºå™¨å­¦ä¹ "],
                "skill_scores": {{"Python": 90, "æ•°æ®åˆ†æ": 85, "æœºå™¨å­¦ä¹ ": 0}}
            }},
            "experience_analysis": {{
                "total_experience": 3.5,
                "relevant_experience": 2.0,
                "company_count": 2,
                "position_progression": ["åˆçº§å¼€å‘", "ä¸­çº§å¼€å‘", "é«˜çº§å¼€å‘"],
                "industry_experience": ["äº’è”ç½‘", "é‡‘èç§‘æŠ€"]
            }},
            "education_analysis": {{
                "degree_level": "æœ¬ç§‘",
                "major": "è®¡ç®—æœºç§‘å­¦",
                "school": "æŸå¤§å­¦",
                "graduation_year": 2020,
                "education_score": 80
            }},
            "strengths": ["ç›¸å…³æŠ€èƒ½åŒ¹é…", "å·¥ä½œç»éªŒä¸°å¯Œ"],
            "weaknesses": ["ç¼ºå°‘æœºå™¨å­¦ä¹ ç»éªŒ", "æ•™è‚²èƒŒæ™¯ä¸€èˆ¬"],
            "potential": "å€™é€‰äººå…·æœ‰æ‰å®çš„æŠ€æœ¯åŸºç¡€ï¼Œå­¦ä¹ èƒ½åŠ›å¼ºï¼Œé€‚åˆè¯¥èŒä½"
        }}
        
        è¯·ç¡®ä¿è¿”å›æœ‰æ•ˆçš„JSONæ ¼å¼ï¼Œmatch_scoreä¸º0-100çš„æ•°å€¼ã€‚
        """
        
        messages = [
            {"role": "user", "content": prompt}
        ]
        
        response = self._call_api(messages)
        
        try:
            json_start = response.find('{')
            json_end = response.rfind('}') + 1
            json_str = response[json_start:json_end]
            
            return json.loads(json_str)
        except:
            # è¿”å›é»˜è®¤åˆ†æç»“æœ
            return {
                "match_score": 70.0,
                "skills_analysis": {
                    "required_skills": [],
                    "candidate_skills": resume_data.get("skills", []),
                    "matched_skills": [],
                    "missing_skills": [],
                    "skill_scores": {}
                },
                "experience_analysis": {
                    "total_experience": len(resume_data.get("experience", [])),
                    "relevant_experience": len(resume_data.get("experience", [])),
                    "company_count": len(set([exp.get("company", "") for exp in resume_data.get("experience", [])])),
                    "position_progression": [exp.get("position", "") for exp in resume_data.get("experience", [])],
                    "industry_experience": []
                },
                "education_analysis": {
                    "degree_level": "æœªçŸ¥",
                    "major": "æœªçŸ¥",
                    "school": "æœªçŸ¥",
                    "graduation_year": None,
                    "education_score": 60
                },
                "strengths": ["æœ‰å·¥ä½œç»éªŒ"],
                "weaknesses": ["ä¿¡æ¯ä¸è¶³"],
                "potential": "éœ€è¦è¿›ä¸€æ­¥äº†è§£"
            }
    
    def generate_interview_questions(self, resume_data: Dict[str, Any], job_description: str, analysis_result: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆä¸ªæ€§åŒ–é¢è¯•é—®é¢˜"""
        prompt = f"""
        åŸºäºä»¥ä¸‹ä¿¡æ¯ï¼Œä¸ºå€™é€‰äººç”Ÿæˆ10ä¸ªä¸ªæ€§åŒ–çš„é¢è¯•é—®é¢˜ï¼š
        
        å€™é€‰äººç®€å†ï¼š
        {json.dumps(resume_data, ensure_ascii=False, indent=2)}
        
        èŒä½æè¿°ï¼š
        {job_description}
        
        åŒ¹é…åˆ†æç»“æœï¼š
        {json.dumps(analysis_result, ensure_ascii=False, indent=2)}
        
        è¯·ç”Ÿæˆæ¶µç›–ä»¥ä¸‹æ–¹é¢çš„é—®é¢˜ï¼š
        1. æŠ€æœ¯èƒ½åŠ›éªŒè¯
        2. é¡¹ç›®ç»éªŒæ·±å…¥
        3. é—®é¢˜è§£å†³èƒ½åŠ›
        4. å›¢é˜Ÿåˆä½œ
        5. å­¦ä¹ èƒ½åŠ›
        6. èŒä¸šè§„åˆ’
        
        è¯·ä»¥JSONæ•°ç»„æ ¼å¼è¿”å›é—®é¢˜åˆ—è¡¨ï¼š
        ["é—®é¢˜1", "é—®é¢˜2", "é—®é¢˜3", ...]
        """
        
        messages = [
            {"role": "user", "content": prompt}
        ]
        
        response = self._call_api(messages)
        
        try:
            json_start = response.find('[')
            json_end = response.rfind(']') + 1
            json_str = response[json_start:json_end]
            
            return json.loads(json_str)
        except:
            # è¿”å›é»˜è®¤é—®é¢˜
            return [
                "è¯·ä»‹ç»ä¸€ä¸‹æ‚¨æœ€æ“…é•¿çš„æŠ€æœ¯æ ˆï¼Ÿ",
                "æè¿°ä¸€ä¸ªæ‚¨è§£å†³è¿‡çš„æŠ€æœ¯éš¾é¢˜ï¼Ÿ",
                "æ‚¨åœ¨å›¢é˜Ÿé¡¹ç›®ä¸­é€šå¸¸æ‰®æ¼”ä»€ä¹ˆè§’è‰²ï¼Ÿ",
                "æ‚¨å¦‚ä½•å­¦ä¹ æ–°çš„æŠ€æœ¯ï¼Ÿ",
                "æ‚¨çš„èŒä¸šè§„åˆ’æ˜¯ä»€ä¹ˆï¼Ÿ",
                "æè¿°ä¸€ä¸ªæ‚¨ä¸»å¯¼çš„é¡¹ç›®ï¼Ÿ",
                "æ‚¨å¦‚ä½•å¤„ç†å·¥ä½œä¸­çš„å‹åŠ›ï¼Ÿ",
                "æ‚¨è®¤ä¸ºè‡ªå·±çš„ä¼˜åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿ",
                "æ‚¨å¸Œæœ›ä»è¿™ä»½å·¥ä½œä¸­è·å¾—ä»€ä¹ˆï¼Ÿ",
                "æ‚¨è¿˜æœ‰ä»€ä¹ˆé—®é¢˜è¦é—®æˆ‘ä»¬ï¼Ÿ"
            ]
    
    def generate_analysis_report(self, resume_data: Dict[str, Any], job_description: str, analysis_result: Dict[str, Any], interview_questions: List[str]) -> str:
        """ç”Ÿæˆå®Œæ•´çš„åˆ†ææŠ¥å‘Š"""
        prompt = f"""
        è¯·åŸºäºä»¥ä¸‹ä¿¡æ¯ç”Ÿæˆä¸€ä»½è¯¦ç»†çš„å€™é€‰äººåˆ†ææŠ¥å‘Šï¼š
        
        å€™é€‰äººä¿¡æ¯ï¼š
        {json.dumps(resume_data, ensure_ascii=False, indent=2)}
        
        èŒä½æè¿°ï¼š
        {job_description}
        
        åŒ¹é…åˆ†æï¼š
        {json.dumps(analysis_result, ensure_ascii=False, indent=2)}
        
        é¢è¯•é—®é¢˜ï¼š
        {json.dumps(interview_questions, ensure_ascii=False, indent=2)}
        
        è¯·ç”Ÿæˆä¸€ä»½ä¸“ä¸šçš„Markdownæ ¼å¼åˆ†ææŠ¥å‘Šï¼ŒåŒ…å«ä»¥ä¸‹éƒ¨åˆ†ï¼š
        
        # ğŸ“Š å€™é€‰äººåˆ†ææŠ¥å‘Š
        
        ## ğŸ‘¤ åŸºæœ¬ä¿¡æ¯
        [å€™é€‰äººå§“åã€è”ç³»æ–¹å¼ç­‰åŸºæœ¬ä¿¡æ¯]
        
        ## ğŸ¯ åŒ¹é…åº¦è¯„ä¼°
        [æ€»ä½“åŒ¹é…åº¦è¯„åˆ†å’Œç®€è¦è¯´æ˜ï¼Œä½¿ç”¨**ç²—ä½“**å¼ºè°ƒå…³é”®ä¿¡æ¯]
        
        ## ğŸ’¼ æŠ€èƒ½åŒ¹é…åˆ†æ
        [æŠ€èƒ½åŒ¹é…æƒ…å†µï¼Œä¼˜åŠ¿å’Œä¸è¶³ï¼Œä½¿ç”¨åˆ—è¡¨æ ¼å¼]
        
        ## ğŸ¢ å·¥ä½œç»éªŒåˆ†æ
        [å·¥ä½œç»éªŒè¯„ä¼°ï¼Œç›¸å…³æ€§å’Œæ·±åº¦]
        
        ## ğŸ“ æ•™è‚²èƒŒæ™¯åˆ†æ
        [æ•™è‚²èƒŒæ™¯ä¸èŒä½è¦æ±‚çš„åŒ¹é…åº¦]
        
        ## âœ… å€™é€‰äººä¼˜åŠ¿
        [å€™é€‰äººçš„ä¸»è¦ä¼˜åŠ¿å’Œäº®ç‚¹ï¼Œä½¿ç”¨åˆ—è¡¨å’Œå¼ºè°ƒ]
        
        ## âš ï¸ æ½œåœ¨ä¸è¶³
        [éœ€è¦å…³æ³¨çš„é—®é¢˜å’Œé£é™©ç‚¹]
        
        ## ğŸš€ å‘å±•æ½œåŠ›
        [å€™é€‰äººæœªæ¥å‘å±•çš„æ½œåŠ›å’Œå»ºè®®]
        
        ## ğŸ’¡ é¢è¯•å»ºè®®
        [åŸºäºåˆ†æç»“æœçš„é¢è¯•é‡ç‚¹å’Œå»ºè®®]
        
        ## ğŸ“ ç»¼åˆè¯„ä»·
        [æ•´ä½“è¯„ä»·å’Œå½•ç”¨å»ºè®®ï¼Œä½¿ç”¨å¼•ç”¨æ ¼å¼çªå‡ºé‡è¦å†…å®¹]
        
        > **æ³¨æ„**ï¼šè¯·ä½¿ç”¨ä¸°å¯Œçš„Markdownæ ¼å¼ï¼ŒåŒ…æ‹¬ç²—ä½“ã€æ–œä½“ã€åˆ—è¡¨ã€å¼•ç”¨å—ç­‰ï¼Œè®©æŠ¥å‘Šæ›´åŠ ä¸“ä¸šå’Œæ˜“è¯»ã€‚
        
        è¯·ç¡®ä¿æŠ¥å‘Šå†…å®¹è¯¦å®ã€å®¢è§‚ï¼Œä¾¿äºHRå’Œé¢è¯•å®˜å‚è€ƒã€‚
        """
        
        messages = [
            {"role": "user", "content": prompt}
        ]
        
        response = self._call_api(messages, temperature=0.8)
        return response
    
    def generate_chart_data(self, analysis_result: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆå›¾è¡¨æ•°æ®"""
        skills_analysis = analysis_result.get("skills_analysis", {})
        experience_analysis = analysis_result.get("experience_analysis", {})
        education_analysis = analysis_result.get("education_analysis", {})
        
        # æŠ€èƒ½åŒ¹é…é›·è¾¾å›¾æ•°æ® - å¢å¼ºæ•°æ®å®Œæ•´æ€§
        skill_scores = skills_analysis.get("skill_scores", {})
        candidate_skills = skills_analysis.get("candidate_skills", [])
        required_skills = skills_analysis.get("required_skills", [])
        
        # å¦‚æœæ²¡æœ‰æŠ€èƒ½åˆ†æ•°ï¼ŒåŸºäºæŠ€èƒ½åˆ—è¡¨ç”Ÿæˆé»˜è®¤åˆ†æ•°
        if not skill_scores and candidate_skills:
            skill_scores = {skill: min(100, 70 + len(skill) * 3) for skill in candidate_skills[:8]}
        
        # å¦‚æœè¿˜æ˜¯æ²¡æœ‰ï¼Œç”ŸæˆåŸºäºèŒä½è¦æ±‚çš„é»˜è®¤æ•°æ®
        if not skill_scores and required_skills:
            skill_scores = {skill: min(100, 60 + len(skill) * 4) for skill in required_skills[:6]}
        
        # æœ€åçš„ä¿åº•æ–¹æ¡ˆ
        if not skill_scores:
            skill_scores = {
                "æŠ€æœ¯èƒ½åŠ›": 70,
                "é¡¹ç›®ç»éªŒ": 65,
                "å­¦ä¹ èƒ½åŠ›": 80,
                "æ²Ÿé€šèƒ½åŠ›": 75,
                "é—®é¢˜è§£å†³": 70
            }
        
        skill_radar_data = {
            "categories": list(skill_scores.keys())[:8],  # é™åˆ¶æœ€å¤š8ä¸ªæŠ€èƒ½
            "values": list(skill_scores.values())[:8]
        }
        
        # ç»éªŒåˆ†ææŸ±çŠ¶å›¾æ•°æ® - å¢å¼ºæ•°æ®å®Œæ•´æ€§
        total_exp = experience_analysis.get("total_experience", 0)
        relevant_exp = experience_analysis.get("relevant_experience", 0)
        
        # å¦‚æœç»éªŒæ•°æ®ä¸º0ï¼Œå°è¯•ä»å…¶ä»–å­—æ®µæ¨æ–­
        if total_exp == 0:
            position_count = len(experience_analysis.get("position_progression", []))
            total_exp = position_count * 1.5 if position_count > 0 else 2.0
        
        if relevant_exp == 0:
            relevant_exp = total_exp * 0.8
        
        experience_bar_data = {
            "categories": ["æ€»ç»éªŒ", "ç›¸å…³ç»éªŒ", "å…¬å¸æ•°é‡"],
            "values": [
                round(total_exp, 1),
                round(relevant_exp, 1),
                experience_analysis.get("company_count", 1)
            ]
        }
        
        # æ•™è‚²èƒŒæ™¯é¥¼å›¾æ•°æ® - å¢å¼ºæ•°æ®å®Œæ•´æ€§
        education_score = education_analysis.get("education_score", 0)
        if education_score == 0:
            # åŸºäºæ•™è‚²èƒŒæ™¯æ¨æ–­åˆ†æ•°
            degree_level = education_analysis.get("degree_level", "æœªçŸ¥")
            if "åšå£«" in degree_level:
                education_score = 95
            elif "ç¡•å£«" in degree_level:
                education_score = 85
            elif "æœ¬ç§‘" in degree_level:
                education_score = 75
            elif "ä¸“ç§‘" in degree_level:
                education_score = 60
            else:
                education_score = 50
        
        education_pie_data = [
            {"name": "æ•™è‚²åŒ¹é…åº¦", "value": education_score},
            {"name": "å…¶ä»–å› ç´ ", "value": 100 - education_score}
        ]
        
        # æ–°å¢ï¼šæŠ€èƒ½å¯¹æ¯”æŸ±çŠ¶å›¾
        skill_comparison_data = {
            "categories": ["å€™é€‰æŠ€èƒ½æ•°", "åŒ¹é…æŠ€èƒ½æ•°", "ç¼ºå¤±æŠ€èƒ½æ•°"],
            "values": [
                len(candidate_skills),
                len(skills_analysis.get("matched_skills", [])),
                len(skills_analysis.get("missing_skills", []))
            ]
        }
        
        # æ–°å¢ï¼šç»¼åˆèƒ½åŠ›é›·è¾¾å›¾
        comprehensive_radar_data = {
            "categories": ["æŠ€æœ¯èƒ½åŠ›", "å·¥ä½œç»éªŒ", "æ•™è‚²èƒŒæ™¯", "å­¦ä¹ èƒ½åŠ›", "æ²Ÿé€šèƒ½åŠ›"],
            "values": [
                min(100, skill_radar_data["values"][0] if skill_radar_data["values"] else 70),
                min(100, (total_exp / 5) * 100),  # 5å¹´ç»éªŒä¸ºæ»¡åˆ†
                education_score,
                min(100, 75 + (total_exp * 5)),  # ç»éªŒè¶Šå¤šå­¦ä¹ èƒ½åŠ›è¶Šå¼º
                min(100, 70 + (experience_analysis.get("company_count", 1) * 10))  # å…¬å¸è¶Šå¤šæ²Ÿé€šèƒ½åŠ›è¶Šå¼º
            ]
        }
        
        return {
            "skill_radar": skill_radar_data,
            "experience_bar": experience_bar_data,
            "education_pie": education_pie_data,
            "skill_comparison": skill_comparison_data,
            "comprehensive_radar": comprehensive_radar_data,
            "match_score": analysis_result.get("match_score", 0)
        }
    
    def comprehensive_analysis(self, resume_data: Dict[str, Any], job_description: str) -> Dict[str, Any]:
        """ç»¼åˆåˆ†æï¼šä¸€æ¬¡APIè°ƒç”¨å®Œæˆæ‰€æœ‰åˆ†æä»»åŠ¡"""
        prompt = f"""
        ä½œä¸ºAIæ‹›è˜ä¸“å®¶ï¼Œè¯·å¯¹ä»¥ä¸‹å€™é€‰äººè¿›è¡Œå…¨é¢çš„æ‹›è˜åˆ†æã€‚

        å€™é€‰äººç®€å†ï¼š
        {json.dumps(resume_data, ensure_ascii=False, indent=2)}

        èŒä½æè¿°ï¼š
        {job_description}

        è¯·æä¾›ä»¥ä¸‹åˆ†æç»“æœï¼Œä»¥JSONæ ¼å¼è¿”å›ï¼š

        1. match_score: æ€»ä½“åŒ¹é…åº¦åˆ†æ•° (0-100)
        2. skills_analysis: æŠ€èƒ½åˆ†æ
           - required_skills: èŒä½è¦æ±‚çš„æŠ€èƒ½åˆ—è¡¨
           - candidate_skills: å€™é€‰äººå…·å¤‡çš„æŠ€èƒ½åˆ—è¡¨
           - matched_skills: åŒ¹é…çš„æŠ€èƒ½åˆ—è¡¨
           - missing_skills: ç¼ºå¤±çš„æŠ€èƒ½åˆ—è¡¨
           - skill_scores: å„æŠ€èƒ½çš„è¯„åˆ† (æŠ€èƒ½å: åˆ†æ•°)
        3. experience_analysis: ç»éªŒåˆ†æ
           - total_experience: æ€»å·¥ä½œç»éªŒå¹´æ•°
           - relevant_experience: ç›¸å…³å·¥ä½œç»éªŒå¹´æ•°
           - company_count: å·¥ä½œå…¬å¸æ•°é‡
           - position_progression: èŒä½å‘å±•è·¯å¾„
           - industry_experience: è¡Œä¸šç»éªŒ
        4. education_analysis: æ•™è‚²èƒŒæ™¯åˆ†æ
           - degree_level: å­¦ä½çº§åˆ«
           - major: ä¸“ä¸š
           - school: å­¦æ ¡
           - graduation_year: æ¯•ä¸šå¹´ä»½
           - education_score: æ•™è‚²åŒ¹é…åº¦åˆ†æ•°
        5. strengths: å€™é€‰äººä¼˜åŠ¿åˆ—è¡¨
        6. weaknesses: å€™é€‰äººä¸è¶³åˆ—è¡¨
        7. potential: å‘å±•æ½œåŠ›è¯„ä¼°

        è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ç»“æœï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡æœ¬æˆ–ä»£ç å—æ ‡è®°ï¼š
        
        {{
            "match_score": 85,
            "skills_analysis": {{
                "required_skills": ["æŠ€èƒ½1", "æŠ€èƒ½2"],
                "candidate_skills": ["æŠ€èƒ½1", "æŠ€èƒ½3"],
                "matched_skills": ["æŠ€èƒ½1"],
                "missing_skills": ["æŠ€èƒ½2"],
                "skill_scores": {{"æŠ€èƒ½1": 90.0, "æŠ€èƒ½2": 60.0}}
            }},
            "experience_analysis": {{
                "total_experience": 3.0,
                "relevant_experience": 2.5,
                "company_count": 2,
                "position_progression": ["åˆçº§", "ä¸­çº§"],
                "industry_experience": ["äº’è”ç½‘", "é‡‘è"]
            }},
            "education_analysis": {{
                "degree_level": "æœ¬ç§‘",
                "major": "è®¡ç®—æœºç§‘å­¦",
                "school": "æŸå¤§å­¦",
                "graduation_year": 2020,
                "education_score": 85.0
            }},
            "strengths": ["ä¼˜åŠ¿1", "ä¼˜åŠ¿2"],
            "weaknesses": ["ä¸è¶³1", "ä¸è¶³2"],
            "potential": "æ½œåŠ›è¯„ä¼°æ–‡æœ¬"
        }}
        """
        
        messages = [
            {"role": "user", "content": prompt}
        ]
        
        response = self._call_api(messages, temperature=0.3)
        
        try:
            # å°è¯•å¤šç§æ–¹å¼æå–JSON
            json_str = None
            
            # æ–¹æ³•1ï¼šæŸ¥æ‰¾å®Œæ•´çš„JSONå¯¹è±¡
            json_start = response.find('{')
            if json_start != -1:
                json_end = response.rfind('}') + 1
                if json_end > json_start:
                    json_str = response[json_start:json_end]
            
            # æ–¹æ³•2ï¼šå¦‚æœæ–¹æ³•1å¤±è´¥ï¼Œå°è¯•æŸ¥æ‰¾JSONä»£ç å—
            if not json_str:
                import re
                json_pattern = r'```json\s*(\{.*?\})\s*```'
                match = re.search(json_pattern, response, re.DOTALL)
                if match:
                    json_str = match.group(1)
            
            # æ–¹æ³•3ï¼šå¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œå°è¯•æŸ¥æ‰¾ä»»ä½•çœ‹èµ·æ¥åƒJSONçš„å†…å®¹
            if not json_str:
                json_pattern = r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}'
                match = re.search(json_pattern, response, re.DOTALL)
                if match:
                    json_str = match.group(0)
            
            if not json_str:
                raise ValueError("æ— æ³•ä»å“åº”ä¸­æå–JSON")
            
            result = json.loads(json_str)
            
            # ç¡®ä¿æ‰€æœ‰å¿…è¦å­—æ®µéƒ½å­˜åœ¨å¹¶æ ¼å¼åŒ–æ­£ç¡®
            if "match_score" not in result:
                result["match_score"] = 0
            if "skills_analysis" not in result:
                result["skills_analysis"] = {}
            if "experience_analysis" not in result:
                result["experience_analysis"] = {}
            if "education_analysis" not in result:
                result["education_analysis"] = {}
            if "strengths" not in result:
                result["strengths"] = []
            if "weaknesses" not in result:
                result["weaknesses"] = []
            if "potential" not in result:
                result["potential"] = "æš‚æ— è¯„ä¼°"
            
            # ä¿®å¤experience_analysisæ ¼å¼
            exp_analysis = result.get("experience_analysis", {})
            if isinstance(exp_analysis.get("total_experience"), str):
                # å°è¯•ä»å­—ç¬¦ä¸²ä¸­æå–æ•°å­—ï¼Œå¦‚"1-2å¹´" -> 1.5
                exp_str = exp_analysis["total_experience"]
                import re
                numbers = re.findall(r'\d+', exp_str)
                if numbers:
                    result["experience_analysis"]["total_experience"] = float(numbers[0])
                else:
                    result["experience_analysis"]["total_experience"] = 0.0
            
            if isinstance(exp_analysis.get("relevant_experience"), str):
                exp_str = exp_analysis["relevant_experience"]
                import re
                numbers = re.findall(r'\d+', exp_str)
                if numbers:
                    result["experience_analysis"]["relevant_experience"] = float(numbers[0])
                else:
                    result["experience_analysis"]["relevant_experience"] = 0.0
            
            if isinstance(exp_analysis.get("position_progression"), str):
                result["experience_analysis"]["position_progression"] = [exp_analysis["position_progression"]]
            
            if isinstance(exp_analysis.get("industry_experience"), str):
                result["experience_analysis"]["industry_experience"] = [exp_analysis["industry_experience"]]
            
            return result
            
        except Exception as e:
            print(f"ç»¼åˆåˆ†æè§£æå¤±è´¥: {e}")
            print(f"åŸå§‹å“åº”: {response[:500]}...")  # æ‰“å°å‰500ä¸ªå­—ç¬¦ç”¨äºè°ƒè¯•
            
            # è¿”å›ä¸€ä¸ªå®Œæ•´çš„é»˜è®¤ç»“æ„ï¼Œç¡®ä¿æ‰€æœ‰å­—æ®µéƒ½æœ‰å€¼
            return self._create_default_analysis_result(resume_data, job_description)
    
    def _create_default_analysis_result(self, resume_data: Dict[str, Any], job_description: str) -> Dict[str, Any]:
        """åˆ›å»ºé»˜è®¤çš„åˆ†æç»“æœç»“æ„"""
        # å°è¯•ä»å“åº”ä¸­æå–ä¸€äº›åŸºæœ¬ä¿¡æ¯
        try:
            import re
            
            # å°è¯•æå–åŒ¹é…åº¦åˆ†æ•°
            match_score = 50.0  # é»˜è®¤ä¸­ç­‰åˆ†æ•°
            score_match = re.search(r'(\d+(?:\.\d+)?)[åˆ†]', str(resume_data))
            if score_match:
                match_score = min(100.0, max(0.0, float(score_match.group(1))))
            
            # åŸºäºç®€å†æ•°æ®ç”Ÿæˆåˆç†çš„é»˜è®¤å€¼
            skills = resume_data.get("skills", [])
            experiences = resume_data.get("experience", [])
            education = resume_data.get("education", [])
            
            # ç”ŸæˆæŠ€èƒ½åˆ†æ
            skills_analysis = {
                "required_skills": self._extract_skills_from_jd(job_description),
                "candidate_skills": skills[:10],  # é™åˆ¶æ•°é‡
                "matched_skills": skills[:5],  # å‡è®¾å‰5ä¸ªæ˜¯åŒ¹é…çš„
                "missing_skills": [],
                "skill_scores": {skill: min(100, 60 + len(skill) * 2) for skill in skills[:5]}
            }
            
            # ç”Ÿæˆç»éªŒåˆ†æ
            experience_analysis = {
                "total_experience": len(experiences) * 1.5,  # ä¼°ç®—
                "relevant_experience": len(experiences) * 1.2,
                "company_count": len(set([exp.get("company", "") for exp in experiences if exp.get("company")])),
                "position_progression": [exp.get("position", "æœªçŸ¥èŒä½") for exp in experiences[:3]],
                "industry_experience": list(set([exp.get("industry", "æœªçŸ¥è¡Œä¸š") for exp in experiences if exp.get("industry")]))
            }
            
            # ç”Ÿæˆæ•™è‚²åˆ†æ
            education_analysis = {
                "degree_level": "æœ¬ç§‘" if education else "æœªçŸ¥",
                "major": education[0].get("major", "æœªçŸ¥ä¸“ä¸š") if education else "æœªçŸ¥ä¸“ä¸š",
                "school": education[0].get("school", "æœªçŸ¥å­¦æ ¡") if education else "æœªçŸ¥å­¦æ ¡",
                "graduation_year": education[0].get("graduation_year") if education else None,
                "education_score": 70.0
            }
            
            # ç”Ÿæˆä¼˜åŠ¿å’Œä¸è¶³
            strengths = [
                "å…·å¤‡ç›¸å…³å·¥ä½œç»éªŒ" if experiences else "æœ‰å­¦ä¹ èƒ½åŠ›",
                "æŒæ¡å¤šç§æŠ€èƒ½" if len(skills) > 3 else "æœ‰åŸºç¡€æŠ€èƒ½",
                "æ•™è‚²èƒŒæ™¯è‰¯å¥½" if education else "æœ‰å‘å±•æ½œåŠ›"
            ]
            
            weaknesses = [
                "ç¼ºå°‘ç‰¹å®šæŠ€èƒ½ç»éªŒ" if len(skills) < 3 else "ç»éªŒç›¸å¯¹æœ‰é™",
                "éœ€è¦è¿›ä¸€æ­¥åŸ¹è®­" if not experiences else "æŠ€èƒ½æ·±åº¦å¾…æå‡"
            ]
            
            potential = "å€™é€‰äººå…·å¤‡åŸºç¡€æ¡ä»¶ï¼Œé€šè¿‡é€‚å½“åŸ¹è®­å¯ä»¥èƒœä»»å·¥ä½œ"
            
            return {
                "match_score": match_score,
                "skills_analysis": skills_analysis,
                "experience_analysis": experience_analysis,
                "education_analysis": education_analysis,
                "strengths": strengths,
                "weaknesses": weaknesses,
                "potential": potential
            }
            
        except Exception as e:
            print(f"åˆ›å»ºé»˜è®¤åˆ†æç»“æœå¤±è´¥: {e}")
            # æœ€åçš„ä¿åº•æ–¹æ¡ˆ
            return {
                "match_score": 50.0,
                "skills_analysis": {
                    "required_skills": [],
                    "candidate_skills": [],
                    "matched_skills": [],
                    "missing_skills": [],
                    "skill_scores": {}
                },
                "experience_analysis": {
                    "total_experience": 0.0,
                    "relevant_experience": 0.0,
                    "company_count": 0,
                    "position_progression": [],
                    "industry_experience": []
                },
                "education_analysis": {
                    "degree_level": "æœªçŸ¥",
                    "major": "æœªçŸ¥",
                    "school": "æœªçŸ¥",
                    "graduation_year": None,
                    "education_score": 60.0
                },
                "strengths": ["æœ‰å­¦ä¹ èƒ½åŠ›"],
                "weaknesses": ["éœ€è¦è¿›ä¸€æ­¥äº†è§£"],
                "potential": "éœ€è¦è¿›ä¸€æ­¥è¯„ä¼°"
            }
    
    def _extract_skills_from_jd(self, job_description: str) -> List[str]:
        """ä»èŒä½æè¿°ä¸­æå–æŠ€èƒ½å…³é”®è¯ - è¦†ç›–å¤šä¸ªå²—ä½å’Œè¡Œä¸š"""
        # æ‰©å±•çš„æŠ€èƒ½å…³é”®è¯åº“ï¼ŒæŒ‰ç±»åˆ«ç»„ç»‡
        skill_keywords = {
            # ç¼–ç¨‹è¯­è¨€
            "programming_languages": [
                "Python", "Java", "JavaScript", "TypeScript", "C++", "C#", "Go", "Rust", "Swift", "Kotlin",
                "PHP", "Ruby", "Scala", "R", "MATLAB", "Perl", "Lua", "Haskell", "Clojure", "Erlang",
                "Shell", "Bash", "PowerShell", "Assembly", "COBOL", "Fortran", "Ada", "Pascal"
            ],
            
            # Webå¼€å‘æ¡†æ¶
            "web_frameworks": [
                "React", "Vue", "Angular", "Svelte", "Next.js", "Nuxt.js", "SvelteKit",
                "Django", "Flask", "FastAPI", "Spring Boot", "Spring MVC", "Spring Security",
                "Express.js", "Koa.js", "Nest.js", "Laravel", "Symfony", "CodeIgniter",
                "Ruby on Rails", "Sinatra", "ASP.NET", "ASP.NET Core", "Blazor", "WebAPI",
                "Gin", "Fiber", "Echo", "Gorilla", "Buffalo"
            ],
            
            # æ•°æ®åº“æŠ€æœ¯
            "databases": [
                "MySQL", "PostgreSQL", "Oracle", "SQL Server", "SQLite", "MariaDB",
                "MongoDB", "Redis", "Cassandra", "CouchDB", "Neo4j", "Elasticsearch",
                "InfluxDB", "TimescaleDB", "ClickHouse", "BigQuery", "Snowflake",
                "DynamoDB", "Firebase", "Supabase", "PlanetScale", "CockroachDB"
            ],
            
            # äº‘æœåŠ¡å’ŒDevOps
            "cloud_devops": [
                "AWS", "Azure", "GCP", "é˜¿é‡Œäº‘", "è…¾è®¯äº‘", "åä¸ºäº‘", "ç™¾åº¦äº‘",
                "Docker", "Kubernetes", "Jenkins", "GitLab CI", "GitHub Actions",
                "Terraform", "Ansible", "Chef", "Puppet", "SaltStack",
                "Prometheus", "Grafana", "ELK Stack", "Splunk", "Datadog",
                "Istio", "Linkerd", "Helm", "ArgoCD", "Tekton"
            ],
            
            # ç§»åŠ¨å¼€å‘
            "mobile_development": [
                "React Native", "Flutter", "Xamarin", "Ionic", "Cordova", "PhoneGap",
                "Android Studio", "Xcode", "Unity", "Unreal Engine", "Godot",
                "iOSå¼€å‘", "Androidå¼€å‘", "è·¨å¹³å°å¼€å‘", "åŸç”Ÿå¼€å‘", "æ··åˆå¼€å‘"
            ],
            
            # AIå’Œæœºå™¨å­¦ä¹ 
            "ai_ml": [
                "æœºå™¨å­¦ä¹ ", "æ·±åº¦å­¦ä¹ ", "äººå·¥æ™ºèƒ½", "ç¥ç»ç½‘ç»œ", "è®¡ç®—æœºè§†è§‰", "è‡ªç„¶è¯­è¨€å¤„ç†",
                "TensorFlow", "PyTorch", "Keras", "Scikit-learn", "OpenCV", "NLTK",
                "Pandas", "NumPy", "Matplotlib", "Seaborn", "Plotly", "Jupyter",
                "Hugging Face", "Transformers", "BERT", "GPT", "LLM", "å¤§è¯­è¨€æ¨¡å‹",
                "æ•°æ®åˆ†æ", "æ•°æ®æŒ–æ˜", "æ•°æ®å¯è§†åŒ–", "ç»Ÿè®¡å­¦ä¹ ", "å¼ºåŒ–å­¦ä¹ "
            ],
            
            # å¤§æ•°æ®æŠ€æœ¯
            "big_data": [
                "Hadoop", "Spark", "Kafka", "Storm", "Flink", "Hive", "Pig", "HBase",
                "å¤§æ•°æ®", "æ•°æ®ä»“åº“", "ETL", "æ•°æ®æ¹–", "å®æ—¶è®¡ç®—", "æ‰¹å¤„ç†",
                "Apache Airflow", "Apache Beam", "Apache NiFi", "DataX", "MaxCompute"
            ],
            
            # æµ‹è¯•å’Œè´¨é‡ä¿è¯
            "testing_qa": [
                "å•å…ƒæµ‹è¯•", "é›†æˆæµ‹è¯•", "ç«¯åˆ°ç«¯æµ‹è¯•", "æ€§èƒ½æµ‹è¯•", "å®‰å…¨æµ‹è¯•", "è‡ªåŠ¨åŒ–æµ‹è¯•",
                "Jest", "Mocha", "Chai", "Cypress", "Selenium", "Playwright", "TestCafe",
                "JUnit", "TestNG", "Mockito", "PowerMock", "Jest", "Enzyme", "Testing Library"
            ],
            
            # å®‰å…¨æŠ€æœ¯
            "security": [
                "ç½‘ç»œå®‰å…¨", "ä¿¡æ¯å®‰å…¨", "æ•°æ®å®‰å…¨", "åº”ç”¨å®‰å…¨", "äº‘å®‰å…¨", "å®‰å…¨å®¡è®¡",
                "æ¸—é€æµ‹è¯•", "æ¼æ´æ‰«æ", "å®‰å…¨ç¼–ç ", "åŠ å¯†ç®—æ³•", "èº«ä»½è®¤è¯", "æƒé™ç®¡ç†",
                "OWASP", "NIST", "ISO27001", "SOC2", "PCI DSS", "GDPR", "æ•°æ®ä¿æŠ¤"
            ],
            
            # äº§å“å’Œç®¡ç†
            "product_management": [
                "äº§å“ç»ç†", "é¡¹ç›®ç®¡ç†", "æ•æ·å¼€å‘", "Scrum", "Kanban", "çœ‹æ¿ç®¡ç†",
                "ç”¨æˆ·ç ”ç©¶", "ç”¨æˆ·ä½“éªŒ", "äº§å“è®¾è®¡", "éœ€æ±‚åˆ†æ", "åŸå‹è®¾è®¡",
                "Jira", "Confluence", "Trello", "Asana", "Notion", "Figma", "Sketch"
            ],
            
            # è½¯æŠ€èƒ½
            "soft_skills": [
                "æ²Ÿé€šèƒ½åŠ›", "å›¢é˜Ÿåä½œ", "é¢†å¯¼åŠ›", "å­¦ä¹ èƒ½åŠ›", "è§£å†³é—®é¢˜", "åˆ›æ–°æ€ç»´",
                "é¡¹ç›®ç®¡ç†", "æ—¶é—´ç®¡ç†", "å‹åŠ›ç®¡ç†", "å®¢æˆ·æœåŠ¡", "æ¼”è®²èƒ½åŠ›", "å†™ä½œèƒ½åŠ›",
                "è‹±è¯­", "æ—¥è¯­", "éŸ©è¯­", "æ³•è¯­", "å¾·è¯­", "è¥¿ç­ç‰™è¯­", "å¤šè¯­è¨€"
            ],
            
            # è¡Œä¸šç‰¹å®šæŠ€èƒ½
            "industry_specific": [
                # é‡‘èç§‘æŠ€
                "é‡‘èç§‘æŠ€", "åŒºå—é“¾", "æ•°å­—è´§å¸", "æ”¯ä»˜ç³»ç»Ÿ", "é£æ§", "åæ¬ºè¯ˆ",
                "é‡åŒ–äº¤æ˜“", "ç®—æ³•äº¤æ˜“", "é«˜é¢‘äº¤æ˜“", "é‡‘èå»ºæ¨¡", "é£é™©ç®¡ç†",
                
                # ç”µå•†
                "ç”µå•†", "é›¶å”®", "ä¾›åº”é“¾", "åº“å­˜ç®¡ç†", "è®¢å•å¤„ç†", "æ”¯ä»˜ç½‘å…³",
                "æ¨èç³»ç»Ÿ", "æœç´¢å¼•æ“", "å•†å“ç®¡ç†", "è¥é”€è‡ªåŠ¨åŒ–",
                
                # æ¸¸æˆå¼€å‘
                "æ¸¸æˆå¼€å‘", "æ¸¸æˆå¼•æ“", "æ¸¸æˆè®¾è®¡", "3Då»ºæ¨¡", "åŠ¨ç”»åˆ¶ä½œ", "éŸ³æ•ˆè®¾è®¡",
                "æ¸¸æˆç­–åˆ’", "å…³å¡è®¾è®¡", "ç”¨æˆ·ç•Œé¢è®¾è®¡", "æ¸¸æˆæµ‹è¯•",
                
                # åŒ»ç–—å¥åº·
                "åŒ»ç–—ä¿¡æ¯åŒ–", "å¥åº·ç®¡ç†", "åŒ»ç–—æ•°æ®", "è¿œç¨‹åŒ»ç–—", "åŒ»ç–—è®¾å¤‡", "è¯ç‰©ç ”å‘",
                "ä¸´åºŠè¯•éªŒ", "åŒ»ç–—å½±åƒ", "ç”µå­ç—…å†", "å¥åº·ç›‘æµ‹",
                
                # æ•™è‚²ç§‘æŠ€
                "åœ¨çº¿æ•™è‚²", "æ•™è‚²æŠ€æœ¯", "å­¦ä¹ ç®¡ç†ç³»ç»Ÿ", "è¯¾ç¨‹è®¾è®¡", "å­¦ä¹ åˆ†æ", "æ™ºèƒ½è¾…å¯¼",
                "è™šæ‹Ÿç°å®", "å¢å¼ºç°å®", "æ··åˆç°å®", "æ²‰æµ¸å¼å­¦ä¹ ",
                
                # æ±½è½¦ç§‘æŠ€
                "è‡ªåŠ¨é©¾é©¶", "è½¦è”ç½‘", "æ™ºèƒ½æ±½è½¦", "æ–°èƒ½æºæ±½è½¦", "æ±½è½¦ç”µå­", "è½¦è½½ç³»ç»Ÿ",
                "ADAS", "V2X", "æ±½è½¦è½¯ä»¶", "è½¦è½½å¨±ä¹ç³»ç»Ÿ",
                
                # ç‰©è”ç½‘
                "ç‰©è”ç½‘", "IoT", "ä¼ æ„Ÿå™¨", "åµŒå…¥å¼å¼€å‘", "è¾¹ç¼˜è®¡ç®—", "æ™ºèƒ½ç¡¬ä»¶",
                "å·¥ä¸š4.0", "æ™ºèƒ½åˆ¶é€ ", "æ™ºæ…§åŸå¸‚", "æ™ºèƒ½å®¶å±…"
            ],
            
            # è®¾è®¡æŠ€èƒ½
            "design_skills": [
                "UIè®¾è®¡", "UXè®¾è®¡", "å¹³é¢è®¾è®¡", "è§†è§‰è®¾è®¡", "äº¤äº’è®¾è®¡", "äº§å“è®¾è®¡",
                "Adobe Photoshop", "Adobe Illustrator", "Adobe XD", "Figma", "Sketch",
                "InVision", "Principle", "Framer", "Protopie", "Origami Studio",
                "ç”¨æˆ·ç ”ç©¶", "å¯ç”¨æ€§æµ‹è¯•", "ä¿¡æ¯æ¶æ„", "è®¾è®¡ç³»ç»Ÿ", "å“ç‰Œè®¾è®¡"
            ],
            
            # è¥é”€å’Œè¿è¥
            "marketing_operations": [
                "æ•°å­—è¥é”€", "ç¤¾äº¤åª’ä½“è¥é”€", "å†…å®¹è¥é”€", "æœç´¢å¼•æ“ä¼˜åŒ–", "æœç´¢å¼•æ“è¥é”€",
                "Google Analytics", "Facebook Ads", "Google Ads", "å¾®ä¿¡è¥é”€", "æŠ–éŸ³è¥é”€",
                "ç”¨æˆ·å¢é•¿", "ç”¨æˆ·è¿è¥", "ç¤¾ç¾¤è¿è¥", "æ´»åŠ¨ç­–åˆ’", "å“ç‰Œæ¨å¹¿",
                "æ•°æ®åˆ†æ", "A/Bæµ‹è¯•", "è½¬åŒ–ç‡ä¼˜åŒ–", "ç”¨æˆ·ç”»åƒ", "ç²¾å‡†è¥é”€"
            ]
        }
        
        found_skills = []
        jd_lower = job_description.lower()
        
        # éå†æ‰€æœ‰æŠ€èƒ½ç±»åˆ«
        for category, skills in skill_keywords.items():
            for skill in skills:
                if skill.lower() in jd_lower:
                    found_skills.append(skill)
        
        # å»é‡å¹¶é™åˆ¶æ•°é‡
        unique_skills = list(dict.fromkeys(found_skills))  # ä¿æŒé¡ºåºçš„å»é‡
        return unique_skills[:15]  # å¢åŠ åˆ°15ä¸ªæŠ€èƒ½
