"""
AIåˆ†æå¤„ç†API
"""
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session
from database import get_db
from models import (
    Candidate, 
    JobDescription, 
    AnalysisResult, 
    ProcessRequest, 
    AnalysisResultResponse,
    SkillAnalysis,
    ExperienceAnalysis,
    EducationAnalysis,
    CandidateProfile
)
from ai_client import ZhipuClient
from mock_ai_client import MockAIClient
from utils import calculate_match_score
import json
import os
from datetime import datetime

router = APIRouter(prefix="/api", tags=["process"])

@router.post("/process", response_model=AnalysisResultResponse)
async def process_analysis(
    request: ProcessRequest,
    db: Session = Depends(get_db)
):
    """å¤„ç†ç®€å†åˆ†æå’ŒåŒ¹é…"""
    try:
        # è·å–å€™é€‰äººä¿¡æ¯
        candidate = db.query(Candidate).filter(Candidate.id == request.file_id).first()
        if not candidate:
            raise HTTPException(status_code=404, detail="å€™é€‰äººæ–‡ä»¶ä¸å­˜åœ¨")
        
        if not candidate.resume_content:
            raise HTTPException(status_code=400, detail="ç®€å†å†…å®¹ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œåˆ†æ")
        
        # ä¿å­˜èŒä½æè¿°
        job_desc = JobDescription(
            candidate_id=request.file_id,
            job_description=request.job_description
        )
        db.add(job_desc)
        db.commit()
        db.refresh(job_desc)
        
        # åˆå§‹åŒ–AIå®¢æˆ·ç«¯ï¼ˆæ ¹æ®ç¯å¢ƒå˜é‡é€‰æ‹©ï¼‰
        use_mock = os.getenv("USE_MOCK_AI", "true").lower() == "true"
        if use_mock:
            ai_client = MockAIClient()
            print("ä½¿ç”¨æ¨¡æ‹ŸAIå®¢æˆ·ç«¯")
        else:
            ai_client = ZhipuClient()
            print("ä½¿ç”¨çœŸå®AIå®¢æˆ·ç«¯")
        
        # è¶…çº§ä¼˜åŒ–çš„AIåˆ†ææµç¨‹ï¼šå‡å°‘APIè°ƒç”¨æ¬¡æ•°
        print("ğŸš€ å¼€å§‹è¶…çº§ä¼˜åŒ–AIåˆ†æ...")
        
        # ç¬¬ä¸€æ­¥ï¼šè§£æç®€å†
        print("ğŸ“„ è§£æç®€å†...")
        resume_data = ai_client.parse_resume(candidate.resume_content)
        print("âœ… ç®€å†è§£æå®Œæˆ")
        
        # ç¬¬äºŒæ­¥ï¼šç»¼åˆåˆ†æï¼ˆä¸€æ¬¡APIè°ƒç”¨å®Œæˆæ‰€æœ‰åˆ†æï¼‰
        print("ğŸ¯ æ‰§è¡Œç»¼åˆåˆ†æï¼ˆåŒ¹é…åº¦+æŠ€èƒ½+ç»éªŒ+æ•™è‚²+ä¼˜åŠ¿åŠ£åŠ¿+æ½œåŠ›ï¼‰...")
        analysis_result = ai_client.comprehensive_analysis(resume_data, request.job_description)
        print("âœ… ç»¼åˆåˆ†æå®Œæˆ")
        
        # ç¬¬ä¸‰æ­¥ï¼šç”Ÿæˆå›¾è¡¨æ•°æ®å’ŒæŠ¥å‘Šï¼ˆä¸åŒ…å«é¢è¯•é—®é¢˜ï¼‰
        import concurrent.futures
        
        print("ğŸ”„ å¹¶å‘æ‰§è¡Œï¼šç”Ÿæˆå›¾è¡¨æ•°æ®å’Œåˆ†ææŠ¥å‘Š...")
        with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:
            # æäº¤å›¾è¡¨æ•°æ®ç”Ÿæˆä»»åŠ¡
            chart_future = executor.submit(
                ai_client.generate_chart_data, analysis_result
            )
            
            # æäº¤æŠ¥å‘Šç”Ÿæˆä»»åŠ¡ï¼ˆä¸åŒ…å«é¢è¯•é—®é¢˜ï¼‰
            report_future = executor.submit(
                ai_client.generate_analysis_report, resume_data, request.job_description, analysis_result, []
            )
            
            # ç­‰å¾…ä¸¤ä¸ªä»»åŠ¡å®Œæˆ
            chart_data = chart_future.result()
            analysis_report = report_future.result()
            
        print("âœ… å›¾è¡¨æ•°æ®å’Œåˆ†ææŠ¥å‘Šç”Ÿæˆå®Œæˆ")
        
        print("ğŸ‰ è¶…çº§ä¼˜åŒ–AIåˆ†æå®Œæˆï¼æ€»è€—æ—¶å¤§å¹…å‡å°‘ï¼")
        
        # åˆ›å»ºå€™é€‰äººç”»åƒ
        candidate_profile = CandidateProfile(
            name=resume_data.get("name", "æœªçŸ¥"),
            contact_info=resume_data.get("contact_info", {}),
            summary=resume_data.get("summary", ""),
            strengths=analysis_result.get("strengths", []),
            weaknesses=analysis_result.get("weaknesses", []),
            potential=analysis_result.get("potential", "")
        )
        
        # ä¿å­˜åˆ†æç»“æœ
        db_analysis = AnalysisResult(
            candidate_id=request.file_id,
            job_description_id=job_desc.id,
            match_score=analysis_result.get("match_score", 0),
            skills_analysis=analysis_result.get("skills_analysis", {}),
            experience_analysis=analysis_result.get("experience_analysis", {}),
            education_analysis=analysis_result.get("education_analysis", {}),
            interview_questions=[],  # åˆå§‹ä¸ºç©º
            questions_generated=False,  # æ ‡è®°ä¸ºæœªç”Ÿæˆ
            candidate_profile=candidate_profile.dict(),
            analysis_report=analysis_report,
            chart_data=chart_data
        )
        db.add(db_analysis)
        db.commit()
        db.refresh(db_analysis)
        
        # æ„å»ºå“åº”æ•°æ®
        print(f"Debug - analysis_result keys: {list(analysis_result.keys())}")
        print(f"Debug - match_score: {analysis_result.get('match_score')}")
        
        response_data = AnalysisResultResponse(
            match_score=analysis_result.get("match_score", 0),
            skills_analysis=SkillAnalysis(**analysis_result.get("skills_analysis", {})),
            experience_analysis=ExperienceAnalysis(**analysis_result.get("experience_analysis", {})),
            education_analysis=EducationAnalysis(**analysis_result.get("education_analysis", {})),
            interview_questions=[],  # åˆå§‹ä¸ºç©ºï¼Œä¸è¿”å›é¢è¯•é—®é¢˜
            candidate_profile=candidate_profile,
            analysis_report=analysis_report,
            chart_data=chart_data,
            created_at=datetime.now()
        )
        
        return response_data
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"åˆ†æå¤„ç†å¤±è´¥: {str(e)}")

@router.get("/process/{file_id}/history")
async def get_analysis_history(file_id: int, db: Session = Depends(get_db)):
    """è·å–å€™é€‰äººçš„åˆ†æå†å²"""
    candidate = db.query(Candidate).filter(Candidate.id == file_id).first()
    if not candidate:
        raise HTTPException(status_code=404, detail="å€™é€‰äººæ–‡ä»¶ä¸å­˜åœ¨")
    
    # è·å–æ‰€æœ‰åˆ†æç»“æœ
    analyses = db.query(AnalysisResult).filter(
        AnalysisResult.candidate_id == file_id
    ).order_by(AnalysisResult.created_at.desc()).all()
    
    history = []
    for analysis in analyses:
        job_desc = db.query(JobDescription).filter(
            JobDescription.id == analysis.job_description_id
        ).first()
        
        history.append({
            "id": analysis.id,
            "job_description": job_desc.job_description if job_desc else "",
            "match_score": analysis.match_score,
            "created_at": analysis.created_at,
            "updated_at": analysis.updated_at
        })
    
    return {"history": history}

@router.get("/process/{analysis_id}")
async def get_analysis_result(analysis_id: int, db: Session = Depends(get_db)):
    """è·å–ç‰¹å®šåˆ†æç»“æœ"""
    analysis = db.query(AnalysisResult).filter(AnalysisResult.id == analysis_id).first()
    if not analysis:
        raise HTTPException(status_code=404, detail="åˆ†æç»“æœä¸å­˜åœ¨")
    
    # è·å–å…³è”çš„èŒä½æè¿°
    job_desc = db.query(JobDescription).filter(
        JobDescription.id == analysis.job_description_id
    ).first()
    
    return {
        "id": analysis.id,
        "candidate_id": analysis.candidate_id,
        "job_description": job_desc.job_description if job_desc else "",
        "match_score": analysis.match_score,
        "skills_analysis": analysis.skills_analysis,
        "experience_analysis": analysis.experience_analysis,
        "education_analysis": analysis.education_analysis,
        "interview_questions": analysis.interview_questions,
        "candidate_profile": analysis.candidate_profile,
        "analysis_report": analysis.analysis_report,
        "chart_data": analysis.chart_data,
        "created_at": analysis.created_at,
        "updated_at": analysis.updated_at
    }

@router.post("/process/{analysis_id}/regenerate")
async def regenerate_analysis(
    analysis_id: int,
    db: Session = Depends(get_db)
):
    """é‡æ–°ç”Ÿæˆåˆ†æç»“æœ"""
    analysis = db.query(AnalysisResult).filter(AnalysisResult.id == analysis_id).first()
    if not analysis:
        raise HTTPException(status_code=404, detail="åˆ†æç»“æœä¸å­˜åœ¨")
    
    try:
        # è·å–å…³è”æ•°æ®
        candidate = db.query(Candidate).filter(Candidate.id == analysis.candidate_id).first()
        job_desc = db.query(JobDescription).filter(JobDescription.id == analysis.job_description_id).first()
        
        if not candidate or not job_desc:
            raise HTTPException(status_code=404, detail="å…³è”æ•°æ®ä¸å­˜åœ¨")
        
        # é‡æ–°åˆ†æï¼ˆä½¿ç”¨ä¼˜åŒ–æµç¨‹ï¼‰
        use_mock = os.getenv("USE_MOCK_AI", "true").lower() == "true"
        if use_mock:
            ai_client = MockAIClient()
            print("é‡æ–°åˆ†æï¼šä½¿ç”¨æ¨¡æ‹ŸAIå®¢æˆ·ç«¯")
        else:
            ai_client = ZhipuClient()
            print("é‡æ–°åˆ†æï¼šä½¿ç”¨çœŸå®AIå®¢æˆ·ç«¯")
        
        print("ğŸ”„ å¼€å§‹é‡æ–°åˆ†æ...")
        
        # è§£æç®€å†
        resume_data = ai_client.parse_resume(candidate.resume_content)
        print("âœ… ç®€å†è§£æå®Œæˆ")
        
        # ç»¼åˆåˆ†æï¼ˆä¸€æ¬¡APIè°ƒç”¨å®Œæˆæ‰€æœ‰åˆ†æï¼‰
        analysis_result = ai_client.comprehensive_analysis(resume_data, job_desc.job_description)
        print("âœ… ç»¼åˆåˆ†æå®Œæˆ")
        
        # æå–æ•°æ®
        interview_questions = analysis_result.get("interview_questions", [])
        
        # å¹¶å‘ç”Ÿæˆå›¾è¡¨æ•°æ®å’ŒæŠ¥å‘Š
        import concurrent.futures
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:
            chart_future = executor.submit(ai_client.generate_chart_data, analysis_result)
            report_future = executor.submit(
                ai_client.generate_analysis_report, resume_data, job_desc.job_description, analysis_result, interview_questions
            )
            
            chart_data = chart_future.result()
            analysis_report = report_future.result()
        
        print("âœ… é‡æ–°åˆ†æå®Œæˆ")
        
        # æ›´æ–°åˆ†æç»“æœ
        analysis.match_score = analysis_result.get("match_score", 0)
        analysis.skills_analysis = analysis_result.get("skills_analysis", {})
        analysis.experience_analysis = analysis_result.get("experience_analysis", {})
        analysis.education_analysis = analysis_result.get("education_analysis", {})
        analysis.interview_questions = interview_questions
        analysis.analysis_report = analysis_report
        analysis.chart_data = chart_data
        
        db.commit()
        db.refresh(analysis)
        
        return {"message": "åˆ†æç»“æœé‡æ–°ç”ŸæˆæˆåŠŸ", "analysis_id": analysis.id}
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"é‡æ–°ç”Ÿæˆå¤±è´¥: {str(e)}")

@router.post("/process/{file_id}/generate-questions")
async def generate_interview_questions(
    file_id: int,
    db: Session = Depends(get_db)
):
    """ç”Ÿæˆé¢è¯•é—®é¢˜"""
    # é€šè¿‡æ–‡ä»¶IDæ‰¾åˆ°æœ€æ–°çš„åˆ†æç»“æœ
    analysis = db.query(AnalysisResult).filter(
        AnalysisResult.candidate_id == file_id
    ).order_by(AnalysisResult.created_at.desc()).first()
    
    if not analysis:
        raise HTTPException(status_code=404, detail="åˆ†æç»“æœä¸å­˜åœ¨")
    
    # å¦‚æœå·²ç»ç”Ÿæˆè¿‡é¢è¯•é—®é¢˜ï¼Œç›´æ¥è¿”å›
    if analysis.questions_generated:
        return {
            "interview_questions": analysis.interview_questions,
            "questions_generated": True,
            "message": "é¢è¯•é—®é¢˜å·²å­˜åœ¨"
        }
    
    try:
        # è·å–å…³è”æ•°æ®
        candidate = db.query(Candidate).filter(Candidate.id == analysis.candidate_id).first()
        job_desc = db.query(JobDescription).filter(JobDescription.id == analysis.job_description_id).first()
        
        if not candidate or not job_desc:
            raise HTTPException(status_code=404, detail="å…³è”æ•°æ®ä¸å­˜åœ¨")
        
        # åˆå§‹åŒ–AIå®¢æˆ·ç«¯
        use_mock = os.getenv("USE_MOCK_AI", "true").lower() == "true"
        if use_mock:
            ai_client = MockAIClient()
            print("ç”Ÿæˆé¢è¯•é—®é¢˜ï¼šä½¿ç”¨æ¨¡æ‹ŸAIå®¢æˆ·ç«¯")
        else:
            ai_client = ZhipuClient()
            print("ç”Ÿæˆé¢è¯•é—®é¢˜ï¼šä½¿ç”¨çœŸå®AIå®¢æˆ·ç«¯")
        
        print("ğŸ¯ å¼€å§‹ç”Ÿæˆé¢è¯•é—®é¢˜...")
        
        # è§£æç®€å†
        resume_data = ai_client.parse_resume(candidate.resume_content)
        print("âœ… ç®€å†è§£æå®Œæˆ")
        
        # æ„å»ºåˆ†æç»“æœæ•°æ®ç”¨äºç”Ÿæˆé¢è¯•é—®é¢˜
        analysis_data = {
            "match_score": analysis.match_score,
            "skills_analysis": analysis.skills_analysis,
            "experience_analysis": analysis.experience_analysis,
            "education_analysis": analysis.education_analysis,
            "strengths": analysis.candidate_profile.get("strengths", []),
            "weaknesses": analysis.candidate_profile.get("weaknesses", []),
            "potential": analysis.candidate_profile.get("potential", "")
        }
        
        # ç”Ÿæˆé¢è¯•é—®é¢˜
        interview_questions = ai_client.generate_interview_questions(
            resume_data, job_desc.job_description, analysis_data
        )
        print("âœ… é¢è¯•é—®é¢˜ç”Ÿæˆå®Œæˆ")
        
        # æ›´æ–°æ•°æ®åº“
        analysis.interview_questions = interview_questions
        analysis.questions_generated = True
        db.commit()
        db.refresh(analysis)
        
        return {
            "interview_questions": interview_questions,
            "questions_generated": True,
            "message": "é¢è¯•é—®é¢˜ç”ŸæˆæˆåŠŸ"
        }
        
    except Exception as e:
        print(f"ç”Ÿæˆé¢è¯•é—®é¢˜å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"ç”Ÿæˆé¢è¯•é—®é¢˜å¤±è´¥: {str(e)}")
